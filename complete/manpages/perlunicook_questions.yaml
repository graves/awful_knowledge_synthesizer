- prompt: "You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.\n\n\n\nManpage text:\n\nPERLUNICOOK(1)\t       Perl Programmers Reference Guide \tPERLUNICOOK(1)"
  manpageQuestion1: What is the primary purpose of the perlunicook tool?
  manpageQuestion2: How would you use perlunicook to process a string and convert it to its Unicode normalization form?
  manpageQuestion3: Can you provide an example of using perlunicook to apply a specific Unicode cooking operation, such as canonical decomposition?

- prompt: "You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.\n\n\n\nManpage text:\n\nNAME\n       perlunicook - cookbookish examples of handling Unicode in Perl\n\nDESCRIPTION\n       This manpage contains short recipes demonstrating how to handle common\n       Unicode operations in Perl, plus one complete program at the end. Any\n       undeclared variables in individual recipes are assumed to have a\n       previous appropriate value in them.\n\nEXAMPLES\n   X 0: Standard preamble\n       Unless otherwise notes, all examples below require this standard\n       preamble to work correctly, with the \"#!\" adjusted to work on your\n       system:\n\n\t#!/usr/bin/env perl\n\n\tuse utf8;      # so literals and identifiers can be in UTF-8\n\tuse v5.12;     # or later to get \"unicode_strings\" feature\n\tuse strict;    # quote strings, declare variables\n\tuse warnings;  # on by default\n\tuse warnings  qw(FATAL utf8);\t # fatalize encoding glitches\n\tuse open      qw(:std :encoding(UTF-8)); # undeclared streams in UTF-8\n\tuse charnames qw(:full :short);  # unneeded in v5.16\n\n       This does make even Unix programmers \"binmode\" your binary streams, or\n       open them with \":raw\", but that's the only way to get at them portably\n       anyway."
  manpageQuestion1: What is the primary purpose of the perlunicook tool?
  manpageQuestion2: How would you use perlunicook to handle Unicode normalization in a Perl script?
  manpageQuestion3: Can you provide an example of using perlunicook to demonstrate the handling of Unicode characters in a Perl script?

- prompt: "You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.\n\n\n\nManpage text:\n\nWARNING: \"use autodie\" (pre 2.26) and \"use open\" do not get along with\n       each other.\n\n   X 1: Generic Unicode-savvy filter\n       Always decompose on the way in, then recompose on the way out.\n\n\tuse Unicode::Normalize;\n\n\twhile (<>) {\n\t    $_ = NFD($_);   # decompose + reorder canonically\n\t    ...\n\t} continue {\n\t    print NFC($_);  # recompose (where possible) + reorder canonically\n\t}\n\n   X 2: Fine-tuning Unicode warnings\n       As of v5.14, Perl distinguishes three subclasses of UTFX8 warnings.\n\n\tuse v5.14;\t\t    # subwarnings unavailable any earlier\n\tno warnings \"nonchar\";\t    # the 66 forbidden non-characters\n\tno warnings \"surrogate\";    # UTF-16/CESU-8 nonsense\n\tno warnings \"non_unicode\";  # for codepoints over 0x10_FFFF\n\n   X 3: Declare source in utf8 for identifiers and literals\n       Without the all-critical \"use utf8\" declaration, putting UTFX8 in your\n       literals and identifiers wonXt work right.  If you used the standard\n       preamble just given above, this already happened.  If you did, you can\n       do things like this:"
  manpageQuestion1: What is the primary purpose of the perlunicook resource?
  manpageQuestion2: How can you configure perlunicook to suppress specific Unicode warnings such as 'nonchar' and 'surrogate'?
  manpageQuestion3: What command or code example would you use to ensure that Perl treats a file's content as UTF-8 when processing it with perlunicook?

- prompt: "You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.\n\n\n\nManpage text:\n\nuse utf8;\n\n\tmy $measure   = \"Aangstroem\";\n\tmy @Xsoft     = qw( cp852 cp1251 cp1252 );\n\tmy @XXXXXXXXX = qw( XXXX  XXXXX );\n\tmy @X\t     = qw( koi8-f koi8-u koi8-r );\n\tmy $motto     = \"X X X\"; # FAMILY, GROWING HEART, DROMEDARY CAMEL\n\n       If you forget \"use utf8\", high bytes will be misunderstood as separate\n       characters, and nothing will work right.\n\n   X 4: Characters and their numbers\n       The \"ord\" and \"chr\" functions work transparently on all codepoints, not\n       just on ASCII alone X nor in fact, not even just on Unicode alone.\n\n\t# ASCII characters\n\tord(\"A\")\n\tchr(65)\n\n\t# characters from the Basic Multilingual Plane\n\tord(\"X\")\n\tchr(0x3A3)\n\n\t# beyond the BMP\n\tord(\"X\")\t       # MATHEMATICAL ITALIC SMALL N\n\tchr(0x1D45B)\n\n\t# beyond Unicode! (up to MAXINT)\n\tord(\"\\x{20_0000}\")\n\tchr(0x20_0000)\n\n   X 5: Unicode literals by character number\n       In an interpolated literal, whether a double-quoted string or a regex,\n       you may specify a character by its number using the \"\\x{HHHHHH}\"\n       escape."
  manpageQuestion1: What is the primary purpose of the perlunicook tool?
  manpageQuestion2: How would you use perlunicook to convert the ASCII character 'A' to its Unicode code point value?
  manpageQuestion3: Can you provide an example of using perlunicook to convert the Unicode code point 0x3A3 to its corresponding character?

- prompt: "You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.\n\n\n\nManpage text:\n\nString: \"\\x{3a3}\"\n\tRegex:\t/\\x{3a3}/\n\n\tString: \"\\x{1d45b}\"\n\tRegex:\t/\\x{1d45b}/\n\n\t# even non-BMP ranges in regex work fine\n\t/[\\x{1D434}-\\x{1D467}]/\n\n   X 6: Get character name by number\n\tuse charnames ();\n\tmy $name = charnames::viacode(0x03A3);\n\n   X 7: Get character number by name\n\tuse charnames ();\n\tmy $number = charnames::vianame(\"GREEK CAPITAL LETTER SIGMA\");\n\n   X 8: Unicode named characters\n       Use the \"\\N{charname}\" notation to get the character by that name for\n       use in interpolated literals (double-quoted strings and regexes).  In\n       v5.16, there is an implicit\n\n\tuse charnames qw(:full :short);\n\n       But prior to v5.16, you must be explicit about which set of charnames\n       you want.  The \":full\" names are the official Unicode character name,\n       alias, or sequence, which all share a namespace.\n\n\tuse charnames qw(:full :short latin greek);\n\n\t\"\\N{MATHEMATICAL ITALIC SMALL N}\"      # :full\n\t\"\\N{GREEK CAPITAL LETTER SIGMA}\"       # :full\n\n       Anything else is a Perl-specific convenience abbreviation.  Specify one\n       or more scripts by names if you want short names that are script-\n       specific."
  manpageQuestion1: What is the primary purpose of the perlunicook tool?
  manpageQuestion2: How can you retrieve the Unicode name for the character with code 0x03A3 using perlunicook?
  manpageQuestion3: Can you provide an example of how to use the \\

- prompt: "You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.\n\n\n\nManpage text:\n\n\"\\N{Greek:Sigma}\"\t\t       # :short\n\t\"\\N{ae}\"\t\t\t       #  latin\n\t\"\\N{epsilon}\"\t\t\t       #  greek\n\n       The v5.16 release also supports a \":loose\" import for loose matching of\n       character names, which works just like loose matching of property\n       names: that is, it disregards case, whitespace, and underscores:\n\n\t\"\\N{euro sign}\" \t\t       # :loose (from v5.16)\n\n       Starting in v5.32, you can also use\n\n\tqr/\\p{name=euro sign}/\n\n       to get official Unicode named characters in regular expressions.  Loose\n       matching is always done for these.\n\n   X 9: Unicode named sequences\n       These look just like character names but return multiple codepoints.\n       Notice the %vx vector-print functionality in \"printf\".\n\n\tuse charnames qw(:full);\n\tmy $seq = \"\\N{LATIN CAPITAL LETTER A WITH MACRON AND GRAVE}\";\n\tprintf \"U+%v04X\\n\", $seq;\n\tU+0100.0300\n\n   X 10: Custom named characters\n       Use \":alias\" to give your own lexically scoped nicknames to existing\n       characters, or even to give unnamed private-use characters useful\n       names."
  manpageQuestion1: What is the primary purpose of the perlunicook resource?
  manpageQuestion2: How would you use perlunicook to match a Unicode character named 'euro sign' with loose matching?
  manpageQuestion3: Can you provide an example of using perlunicook to convert a Unicode named sequence into its corresponding codepoints?

- prompt: "You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.\n\n\n\nManpage text:\n\nuse charnames \":full\", \":alias\" => {\n\t    ecute => \"LATIN SMALL LETTER E WITH ACUTE\",\n\t    \"APPLE LOGO\" => 0xF8FF, # private use character\n\t};\n\n\t\"\\N{ecute}\"\n\t\"\\N{APPLE LOGO}\"\n\n   X 11: Names of CJK codepoints\n       Sinograms like XXXX come back with character names of \"CJK UNIFIED\n       IDEOGRAPH-6771\" and \"CJK UNIFIED IDEOGRAPH-4EAC\", because their XnamesX\n       vary.  The CPAN \"Unicode::Unihan\" module has a large database for\n       decoding these (and a whole lot more), provided you know how to\n       understand its output.\n\n\t# cpan -i Unicode::Unihan\n\tuse Unicode::Unihan;\n\tmy $str = \"XX\";\n\tmy $unhan = Unicode::Unihan->new;\n\tfor my $lang (qw(Mandarin Cantonese Korean JapaneseOn JapaneseKun)) {\n\t    printf \"CJK $str in %-12s is \", $lang;\n\t    say $unhan->$lang($str);\n\t}\n\n       prints:\n\n\tCJK XX in Mandarin     is DONG1JING1\n\tCJK XX in Cantonese    is dung1ging1\n\tCJK XX in Korean       is TONGKYENG\n\tCJK XX in JapaneseOn   is TOUKYOU KEI KIN\n\tCJK XX in JapaneseKun  is HIGASHI AZUMAMIYAKO"
  manpageQuestion1: What is the primary purpose of the perlunicook module?
  manpageQuestion2: How would you use perlunicook to map the Unicode codepoint 'ecute' to its corresponding character name?
  manpageQuestion3: Can you provide an example of using perlunicook to decode a CJK character like 'XX' into its localized representation in Mandarin?

- prompt: "You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.\n\n\n\nManpage text:\n\nIf you have a specific romanization scheme in mind, use the specific\n       module:\n\n\t# cpan -i Lingua::JA::Romanize::Japanese\n\tuse Lingua::JA::Romanize::Japanese;\n\tmy $k2r = Lingua::JA::Romanize::Japanese->new;\n\tmy $str = \"XX\";\n\tsay \"Japanese for $str is \", $k2r->chars($str);\n\n       prints\n\n\tJapanese for XX is toukyou\n\n   X 12: Explicit encode/decode\n       On rare occasion, such as a database read, you may be given encoded\n       text you need to decode.\n\n\t use Encode qw(encode decode);\n\n\t my $chars = decode(\"shiftjis\", $bytes, 1);\n\t# OR\n\t my $bytes = encode(\"MIME-Header-ISO_2022_JP\", $chars, 1);\n\n       For streams all in the same encoding, don't use encode/decode; instead\n       set the file encoding when you open the file or immediately after with\n       \"binmode\" as described later below.\n\n   X 13: Decode program arguments as utf8\n\t    $ perl -CA ...\n\tor\n\t    $ export PERL_UNICODE=A\n\tor\n\t   use Encode qw(decode);\n\t   @ARGV = map { decode('UTF-8', $_, 1) } @ARGV;\n\n   X 14: Decode program arguments as locale encoding\n\t   # cpan -i Encode::Locale\n\t   use Encode qw(locale);\n\t   use Encode::Locale;"
  manpageQuestion1: What is the primary purpose of the perlunicook resource?
  manpageQuestion2: How can you use perlunicook to decode program arguments as UTF-8 encoding?
  manpageQuestion3: Can you provide an example of using perlunicook to decode a string from Shift_JIS encoding into Unicode characters?

- prompt: "You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.\n\n\n\nManpage text:\n\n# use \"locale\" as an arg to encode/decode\n\t   @ARGV = map { decode(locale => $_, 1) } @ARGV;\n\n   X 15: Declare STD{IN,OUT,ERR} to be utf8\n       Use a command-line option, an environment variable, or else call\n       \"binmode\" explicitly:\n\n\t    $ perl -CS ...\n\tor\n\t    $ export PERL_UNICODE=S\n\tor\n\t    use open qw(:std :encoding(UTF-8));\n\tor\n\t    binmode(STDIN,  \":encoding(UTF-8)\");\n\t    binmode(STDOUT, \":utf8\");\n\t    binmode(STDERR, \":utf8\");\n\n   X 16: Declare STD{IN,OUT,ERR} to be in locale encoding\n\t   # cpan -i Encode::Locale\n\t   use Encode;\n\t   use Encode::Locale;\n\n\t   # or as a stream for binmode or open\n\t   binmode STDIN,  \":encoding(console_in)\"  if -t STDIN;\n\t   binmode STDOUT, \":encoding(console_out)\" if -t STDOUT;\n\t   binmode STDERR, \":encoding(console_out)\" if -t STDERR;\n\n   X 17: Make file I/O default to utf8\n       Files opened without an encoding argument will be in UTF-8:\n\n\t    $ perl -CD ...\n\tor\n\t    $ export PERL_UNICODE=D\n\tor\n\t    use open qw(:encoding(UTF-8));\n\n   X 18: Make all I/O and args default to utf8\n\t    $ perl -CSDA ...\n\tor\n\t    $ export PERL_UNICODE=SDA\n\tor\n\t    use open qw(:std :encoding(UTF-8));\n\t    use Encode qw(decode);\n\t    @ARGV = map { decode('UTF-8', $_, 1) } @ARGV;"
  manpageQuestion1: What is the primary purpose of the perlunicook resource?
  manpageQuestion2: How can you configure Perl to make all input and output streams default to UTF-8 encoding when running a script?
  manpageQuestion3: What is the process for declaring that standard input, output, and error streams should be in locale encoding using Perl?

- prompt: "You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.\n\n\n\nManpage text:\n\nX 19: Open file with specific encoding\n       Specify stream encoding.  This is the normal way to deal with encoded\n       text, not by calling low-level functions.\n\n\t# input file\n\t    open(my $in_file, \"< :encoding(UTF-16)\", \"wintext\");\n\tOR\n\t    open(my $in_file, \"<\", \"wintext\");\n\t    binmode($in_file, \":encoding(UTF-16)\");\n\tTHEN\n\t    my $line = <$in_file>;\n\n\t# output file\n\t    open($out_file, \"> :encoding(cp1252)\", \"wintext\");\n\tOR\n\t    open(my $out_file, \">\", \"wintext\");\n\t    binmode($out_file, \":encoding(cp1252)\");\n\tTHEN\n\t    print $out_file \"some text\\n\";\n\n       More layers than just the encoding can be specified here. For example,\n       the incantation \":raw :encoding(UTF-16LE) :crlf\" includes implicit CRLF\n       handling.\n\n   X 20: Unicode casing\n       Unicode casing is very different from ASCII casing.\n\n\tuc(\"henry X\")  # \"HENRY X\"\n\tuc(\"tschuess\")\t # \"TSCHUeSS\"  notice ss => SS\n\n\t# both are true:\n\t\"tschuess\"  =~ /TSCHUeSS/i   # notice ss => SS\n\t\"XXXXXXX\" =~ /XXXXXXX/i   # notice X,X,X sameness"
  manpageQuestion1: What is the primary purpose of the perlunicook resource?
  manpageQuestion2: How can you use perlunicook to read a file encoded in UTF-16 and write it to a file encoded in cp1252?
  manpageQuestion3: What is the effect of using uc on a Unicode string like 'tschuess'?

- prompt: "You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.\n\n\n\nManpage text:\n\nX 21: Unicode case-insensitive comparisons\n       Also available in the CPAN Unicode::CaseFold module, the new \"fc\"\n       XfoldcaseX function from v5.16 grants access to the same Unicode\n       casefolding as the \"/i\" pattern modifier has always used:\n\n\tuse feature \"fc\"; # fc() function is from v5.16\n\n\t# sort case-insensitively\n\tmy @sorted = sort { fc($a) cmp fc($b) } @list;\n\n\t# both are true:\n\tfc(\"tschuess\")\teq fc(\"TSCHUeSS\")\n\tfc(\"XXXXXXX\") eq fc(\"XXXXXXX\")\n\n   X 22: Match Unicode linebreak sequence in regex\n       A Unicode linebreak matches the two-character CRLF grapheme or any of\n       seven vertical whitespace characters.  Good for dealing with textfiles\n       coming from different operating systems.\n\n\t\\R\n\n\ts/\\R/\\n/g;  # normalize all linebreaks to \\n\n\n   X 23: Get character category\n       Find the general category of a numeric codepoint.\n\n\tuse Unicode::UCD qw(charinfo);\n\tmy $cat = charinfo(0x3A3)->{category};\t# \"Lu\"\n\n   X 24: Disabling Unicode-awareness in builtin charclasses\n       Disable \"\\w\", \"\\b\", \"\\s\", \"\\d\", and the POSIX classes from working\n       correctly on Unicode either in this scope, or in just one regex."
  manpageQuestion1: What is the primary purpose of the perlunicook module?
  manpageQuestion2: How can you use perlunicook to perform case-insensitive sorting of a list of strings in Perl?
  manpageQuestion3: Can you provide an example of using perlunicook to determine the general category of a Unicode codepoint?

- prompt: "You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.\n\n\n\nManpage text:\n\nuse v5.14;\n\tuse re \"/a\";\n\n\t# OR\n\n\tmy($num) = $str =~ /(\\d+)/a;\n\n       Or use specific un-Unicode properties, like \"\\p{ahex}\" and\n       \"\\p{POSIX_Digit\"}.  Properties still work normally no matter what\n       charset modifiers (\"/d /u /l /a /aa\") should be effect.\n\n   X 25: Match Unicode properties in regex with \\p, \\P\n       These all match a single codepoint with the given property.  Use \"\\P\"\n       in place of \"\\p\" to match one codepoint lacking that property.\n\n\t\\pL, \\pN, \\pS, \\pP, \\pM, \\pZ, \\pC\n\t\\p{Sk}, \\p{Ps}, \\p{Lt}\n\t\\p{alpha}, \\p{upper}, \\p{lower}\n\t\\p{Latin}, \\p{Greek}\n\t\\p{script_extensions=Latin}, \\p{scx=Greek}\n\t\\p{East_Asian_Width=Wide}, \\p{EA=W}\n\t\\p{Line_Break=Hyphen}, \\p{LB=HY}\n\t\\p{Numeric_Value=4}, \\p{NV=4}\n\n   X 26: Custom character properties\n       Define at compile-time your own custom character properties for use in\n       regexes.\n\n\t# using private-use characters\n\tsub In_Tengwar { \"E000\\tE07F\\n\" }\n\n\tif (/\\p{In_Tengwar}/) { ... }\n\n\t# blending existing properties\n\tsub Is_GraecoRoman_Title {<<'END_OF_SET'}\n\t+utf8::IsLatin\n\t+utf8::IsGreek\n\t&utf8::IsTitle\n\tEND_OF_SET"
  manpageQuestion1: What is the primary purpose of the perlunicook tool?
  manpageQuestion2: How can you use perlunicook to match a string that contains any Unicode letter character using regex?
  manpageQuestion3: Can you provide an example of defining a custom character property in perlunicook and using it in a regex?

- prompt: "You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.\n\n\n\nManpage text:\n\nif (/\\p{Is_GraecoRoman_Title}/ { ... }\n\n   X 27: Unicode normalization\n       Typically render into NFD on input and NFC on output. Using NFKC or\n       NFKD functions improves recall on searches, assuming you've already\n       done to the same text to be searched. Note that this is about much more\n       than just pre- combined compatibility glyphs; it also reorders marks\n       according to their canonical combining classes and weeds out\n       singletons.\n\n\tuse Unicode::Normalize;\n\tmy $nfd  = NFD($orig);\n\tmy $nfc  = NFC($orig);\n\tmy $nfkd = NFKD($orig);\n\tmy $nfkc = NFKC($orig);\n\n   X 28: Convert non-ASCII Unicode numerics\n       Unless youXve used \"/a\" or \"/aa\", \"\\d\" matches more than ASCII digits\n       only, but PerlXs implicit string-to-number conversion does not current\n       recognize these.  HereXs how to convert such strings manually.\n\n\tuse v5.14;  # needed for num() function\n\tuse Unicode::UCD qw(num);\n\tmy $str = \"got X and XXXX and X and here\";\n\tmy @nums = ();\n\twhile ($str =~ /(\\d+|\\N)/g) {  # not just ASCII!\n\t   push @nums, num($1);\n\t}\n\tsay \"@nums\";   #     12      4567      0.875"
  manpageQuestion1: What is the primary purpose of the perlunicook resource?
  manpageQuestion2: How can you convert a string containing non-ASCII Unicode numerics to their numeric values using perlunicook?
  manpageQuestion3: What is the recommended approach for normalizing Unicode text in perlunicook to ensure consistent processing?

- prompt: "You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.\n\n\n\nManpage text:\n\nuse charnames qw(:full);\n\tmy $nv = num(\"\\N{RUMI DIGIT ONE}\\N{RUMI DIGIT TWO}\");\n\n   X 29: Match Unicode grapheme cluster in regex\n       Programmer-visible XcharactersX are codepoints matched by \"/./s\", but\n       user-visible XcharactersX are graphemes matched by \"/\\X/\".\n\n\t# Find vowel *plus* any combining diacritics,underlining,etc.\n\tmy $nfd = NFD($orig);\n\t$nfd =~ / (?=[aeiou]) \\X /xi\n\n   X 30: Extract by grapheme instead of by codepoint (regex)\n\t# match and grab five first graphemes\n\tmy($first_five) = $str =~ /^ ( \\X{5} ) /x;\n\n   X 31: Extract by grapheme instead of by codepoint (substr)\n\t# cpan -i Unicode::GCString\n\tuse Unicode::GCString;\n\tmy $gcs = Unicode::GCString->new($str);\n\tmy $first_five = $gcs->substr(0, 5);\n\n   X 32: Reverse string by grapheme\n       Reversing by codepoint messes up diacritics, mistakenly converting\n       \"creme brulee\" into \"eelXurb emXerc\" instead of into \"eelurb emerc\"; so\n       reverse by grapheme instead.  Both these approaches work right no\n       matter what normalization the string is in:"
  manpageQuestion1: What is the primary purpose of the perlunicook module?
  manpageQuestion2: How can you use Perl's Unicode::GCString to extract the first five graphemes from a string?
  manpageQuestion3: What is an example of reversing a string by grapheme instead of codepoint in Perl using the Unicode::GCString module?

- prompt: "You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.\n\n\n\nManpage text:\n\n$str = join(\"\", reverse $str =~ /\\X/g);\n\n\t# OR: cpan -i Unicode::GCString\n\tuse Unicode::GCString;\n\t$str = reverse Unicode::GCString->new($str);\n\n   X 33: String length in graphemes\n       The string \"brulee\" has six graphemes but up to eight codepoints.  This\n       counts by grapheme, not by codepoint:\n\n\tmy $str = \"brulee\";\n\tmy $count = 0;\n\twhile ($str =~ /\\X/g) { $count++ }\n\n\t # OR: cpan -i Unicode::GCString\n\tuse Unicode::GCString;\n\tmy $gcs = Unicode::GCString->new($str);\n\tmy $count = $gcs->length;\n\n   X 34: Unicode column-width for printing\n       PerlXs \"printf\", \"sprintf\", and \"format\" think all codepoints take up 1\n       print column, but many take 0 or 2.  Here to show that normalization\n       makes no difference, we print out both forms:\n\n\tuse Unicode::GCString;\n\tuse Unicode::Normalize;\n\n\tmy @words = qw/creme brulee/;\n\t@words = map { NFC($_), NFD($_) } @words;\n\n\tfor my $str (@words) {\n\t    my $gcs = Unicode::GCString->new($str);\n\t    my $cols = $gcs->columns;\n\t    my $pad = \" \" x (10 - $cols);\n\t    say str, $pad, \" |\";\n\t}"
  manpageQuestion1: What is the primary purpose of the perlunicook resource?
  manpageQuestion2: How can you use perlunicook to count the number of graphemes in a string?
  manpageQuestion3: Can you provide an example of using perlunicook to calculate the column-width for a Unicode string?

- prompt: "You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.\n\n\n\nManpage text:\n\ngenerates this to show that it pads correctly no matter the\n       normalization:\n\n\tcreme\t   |\n\tcreXme\t    |\n\tbrulee\t   |\n\tbruXleXe     |\n\n   X 35: Unicode collation\n       Text sorted by numeric codepoint follows no reasonable alphabetic\n       order; use the UCA for sorting text.\n\n\tuse Unicode::Collate;\n\tmy $col = Unicode::Collate->new();\n\tmy @list = $col->sort(@old_list);\n\n       See the ucsort program from the Unicode::Tussle CPAN module for a\n       convenient command-line interface to this module.\n\n   X 36: Case- and accent-insensitive Unicode sort\n       Specify a collation strength of level 1 to ignore case and diacritics,\n       only looking at the basic character.\n\n\tuse Unicode::Collate;\n\tmy $col = Unicode::Collate->new(level => 1);\n\tmy @list = $col->sort(@old_list);\n\n   X 37: Unicode locale collation\n       Some locales have special sorting rules.\n\n\t# either use v5.12, OR: cpan -i Unicode::Collate::Locale\n\tuse Unicode::Collate::Locale;\n\tmy $col = Unicode::Collate::Locale->new(locale => \"de__phonebook\");\n\tmy @list = $col->sort(@old_list);"
  manpageQuestion1: What is the primary purpose of the perlunicook tool?
  manpageQuestion2: How can you use perlunicook to perform a Unicode collation sort that is case-insensitive and ignores accents?
  manpageQuestion3: Can you provide an example of using perlunicook to sort a list of strings according to the German locale's phonebook sorting rules?

- prompt: "You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.\n\n\n\nManpage text:\n\nThe ucsort program mentioned above accepts a \"--locale\" parameter.\n\n   X 38: Making \"cmp\" work on text instead of codepoints\n       Instead of this:\n\n\t@srecs = sort {\n\t    $b->{AGE}\t<=>  $a->{AGE}\n\t\t\t||\n\t    $a->{NAME}\tcmp  $b->{NAME}\n\t} @recs;\n\n       Use this:\n\n\tmy $coll = Unicode::Collate->new();\n\tfor my $rec (@recs) {\n\t    $rec->{NAME_key} = $coll->getSortKey( $rec->{NAME} );\n\t}\n\t@srecs = sort {\n\t    $b->{AGE}\t    <=>  $a->{AGE}\n\t\t\t    ||\n\t    $a->{NAME_key}  cmp  $b->{NAME_key}\n\t} @recs;\n\n   X 39: Case- and accent-insensitive comparisons\n       Use a collator object to compare Unicode text by character instead of\n       by codepoint.\n\n\tuse Unicode::Collate;\n\tmy $es = Unicode::Collate->new(\n\t    level => 1,\n\t    normalization => undef\n\t);\n\n\t # now both are true:\n\t$es->eq(\"Garcia\",  \"GARCIA\" );\n\t$es->eq(\"Marquez\", \"MARQUEZ\");\n\n   X 40: Case- and accent-insensitive locale comparisons\n       Same, but in a specific locale.\n\n\tmy $de = Unicode::Collate::Locale->new(\n\t\t   locale => \"de__phonebook\",\n\t\t );"
  manpageQuestion1: What is the primary purpose of the perlunicook resource?
  manpageQuestion2: How can you use Perl's Unicode::Collate module to perform case-insensitive and accent-insensitive comparisons between strings?
  manpageQuestion3: How do you create a collator object in Perl's Unicode::Collate module to perform locale-specific comparisons, such as for the German 'phonebook' locale?

- prompt: "You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.\n\n\n\nManpage text:\n\n# now this is true:\n\t$de->eq(\"tschuess\", \"TSCHUESS\");  # notice ue => UE, ss => SS\n\n   X 41: Unicode linebreaking\n       Break up text into lines according to Unicode rules.\n\n\t# cpan -i Unicode::LineBreak\n\tuse Unicode::LineBreak;\n\tuse charnames qw(:full);\n\n\tmy $para = \"This is a super\\N{HYPHEN}long string. \" x 20;\n\tmy $fmt = Unicode::LineBreak->new;\n\tprint $fmt->break($para), \"\\n\";\n\n   X 42: Unicode text in DBM hashes, the tedious way\n       Using a regular Perl string as a key or value for a DBM hash will\n       trigger a wide character exception if any codepoints wonXt fit into a\n       byte.  HereXs how to manually manage the translation:\n\n\t   use DB_File;\n\t   use Encode qw(encode decode);\n\t   tie %dbhash, \"DB_File\", \"pathname\";\n\n\t# STORE\n\n\t   # assume $uni_key and $uni_value are abstract Unicode strings\n\t   my $enc_key\t = encode(\"UTF-8\", $uni_key, 1);\n\t   my $enc_value = encode(\"UTF-8\", $uni_value, 1);\n\t   $dbhash{$enc_key} = $enc_value;\n\n\t# FETCH\n\n\t   # assume $uni_key holds a normal Perl string (abstract Unicode)\n\t   my $enc_key\t = encode(\"UTF-8\", $uni_key, 1);\n\t   my $enc_value = $dbhash{$enc_key};\n\t   my $uni_value = decode(\"UTF-8\", $enc_value, 1);"
  manpageQuestion1: What is the primary purpose of the perlunicook resource?
  manpageQuestion2: How can you use perlunicook to break a string into lines according to Unicode linebreaking rules?
  manpageQuestion3: Can you provide an example of using perlunicook to handle Unicode text in DBM hashes by encoding and decoding strings?

- prompt: "You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.\n\n\n\nManpage text:\n\nX 43: Unicode text in DBM hashes, the easy way\n       HereXs how to implicitly manage the translation; all encoding and\n       decoding is done automatically, just as with streams that have a\n       particular encoding attached to them:\n\n\t   use DB_File;\n\t   use DBM_Filter;\n\n\t   my $dbobj = tie %dbhash, \"DB_File\", \"pathname\";\n\t   $dbobj->Filter_Value(\"utf8\");  # this is the magic bit\n\n\t# STORE\n\n\t   # assume $uni_key and $uni_value are abstract Unicode strings\n\t   $dbhash{$uni_key} = $uni_value;\n\n\t # FETCH\n\n\t   # $uni_key holds a normal Perl string (abstract Unicode)\n\t   my $uni_value = $dbhash{$uni_key};\n\n   X 44: PROGRAM: Demo of Unicode collation and printing\n       HereXs a full program showing how to make use of locale-sensitive\n       sorting, Unicode casing, and managing print widths when some of the\n       characters take up zero or two columns, not just one column each time.\n       When run, the following program produces this nicely aligned output:\n\n\t   Creme Brulee....... X2.00\n\t   Eclair............. X1.60\n\t   Fideua............. X4.20\n\t   Hamburger.......... X6.00\n\t   Jamon Serrano...... X4.45\n\t   Linguica........... X7.00\n\t   Pate............... X4.15\n\t   Pears.............. X2.00\n\t   Peches............. X2.25\n\t   Smorbrod........... X5.75\n\t   Spaetzle............ X5.50\n\t   Xorico............. X3.00\n\t   XXXXX.............. X6.50\n\t   XXX............. X4.00\n\t   XXX............. X2.65\n\t   XXXXX......... X8.00\n\t   XXXXXXX..... X1.85\n\t   XX............... X9.99\n\t   XX............... X7.50"
  manpageQuestion1: What is the primary purpose of the perlunicook tool?
  manpageQuestion2: How would you use perlunicook to manage Unicode text in DBM hashes?
  manpageQuestion3: Can you provide an example of using perlunicook to demonstrate Unicode collation and printing?

- prompt: "You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.\n\n\n\nManpage text:\n\nHere's that program; tested on v5.14.\n\n\t#!/usr/bin/env perl\n\t# umenu - demo sorting and printing of Unicode food\n\t#\n\t# (obligatory and increasingly long preamble)\n\t#\n\tuse utf8;\n\tuse v5.14;\t\t\t # for locale sorting\n\tuse strict;\n\tuse warnings;\n\tuse warnings  qw(FATAL utf8);\t # fatalize encoding faults\n\tuse open      qw(:std :encoding(UTF-8)); # undeclared streams in UTF-8\n\tuse charnames qw(:full :short);  # unneeded in v5.16\n\n\t# std modules\n\tuse Unicode::Normalize; \t # std perl distro as of v5.8\n\tuse List::Util qw(max); \t # std perl distro as of v5.10\n\tuse Unicode::Collate::Locale;\t # std perl distro as of v5.14\n\n\t# cpan modules\n\tuse Unicode::GCString;\t\t # from CPAN\n\n\t# forward defs\n\tsub pad($$$);\n\tsub colwidth(_);\n\tsub entitle(_);\n\n\tmy %price = (\n\t    \"XXXXX\"\t\t=> 6.50, # gyros\n\t    \"pears\"\t\t=> 2.00, # like um, pears\n\t    \"linguica\"\t\t=> 7.00, # spicy sausage, Portuguese\n\t    \"xorico\"\t\t=> 3.00, # chorizo sausage, Catalan\n\t    \"hamburger\" \t=> 6.00, # burgermeister meisterburger\n\t    \"eclair\"\t\t=> 1.60, # dessert, French\n\t    \"smorbrod\"\t\t=> 5.75, # sandwiches, Norwegian\n\t    \"spaetzle\"\t\t => 5.50, # Bayerisch noodles, little sparrows\n\t    \"XX\"\t      => 7.50, # bao1 zi5, steamed pork buns, Mandarin\n\t    \"jamon serrano\"\t=> 4.45, # country ham, Spanish\n\t    \"peches\"\t\t=> 2.25, # peaches, French\n\t    \"XXXXXXX\"\t => 1.85, # cream-filled pastry like eclair\n\t    \"XXX\"\t     => 4.00, # makgeolli, Korean rice wine\n\t    \"XX\"\t      => 9.99, # sushi, Japanese\n\t    \"XXX\"\t     => 2.65, # omochi, rice cakes, Japanese\n\t    \"creme brulee\"\t=> 2.00, # crema catalana\n\t    \"fideua\"\t\t=> 4.20, # more noodles, Valencian\n\t\t\t\t\t # (Catalan=fideuada)\n\t    \"pate\"\t\t=> 4.15, # gooseliver paste, French\n\t    \"XXXXX\"\t   => 8.00, # okonomiyaki, Japanese\n\t);"
  manpageQuestion1: What is the primary purpose of the perlunicook tool?
  manpageQuestion2: How would you use perlunicook to sort a list of Unicode strings in the user's locale order?
  manpageQuestion3: Can you provide an example of using perlunicook to process a list of Unicode food items with specific sorting and formatting requirements?

- prompt: "You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.\n\n\n\nManpage text:\n\nmy $width = 5 + max map { colwidth } keys %price;\n\n\t# So the Asian stuff comes out in an order that someone\n\t# who reads those scripts won't freak out over; the\n\t# CJK stuff will be in JIS X 0208 order that way.\n\tmy $coll  = Unicode::Collate::Locale->new(locale => \"ja\");\n\n\tfor my $item ($coll->sort(keys %price)) {\n\t    print pad(entitle($item), $width, \".\");\n\t    printf \" X%.2f\\n\", $price{$item};\n\t}\n\n\tsub pad($$$) {\n\t    my($str, $width, $padchar) = @_;\n\t    return $str . ($padchar x ($width - colwidth($str)));\n\t}\n\n\tsub colwidth(_) {\n\t    my($str) = @_;\n\t    return Unicode::GCString->new($str)->columns;\n\t}\n\n\tsub entitle(_) {\n\t    my($str) = @_;\n\t    $str =~ s{ (?=\\pL)(\\S)     (\\S*) }\n\t\t     { ucfirst($1) . lc($2)  }xge;\n\t    return $str;\n\t}\n\nSEE ALSO\n       See these manpages, some of which are CPAN modules: perlunicode,\n       perluniprops, perlre, perlrecharclass, perluniintro, perlunitut,\n       perlunifaq, PerlIO, DB_File, DBM_Filter, DBM_Filter::utf8, Encode,\n       Encode::Locale, Unicode::UCD, Unicode::Normalize, Unicode::GCString,\n       Unicode::LineBreak, Unicode::Collate, Unicode::Collate::Locale,\n       Unicode::Unihan, Unicode::CaseFold, Unicode::Tussle,\n       Lingua::JA::Romanize::Japanese, Lingua::ZH::Romanize::Pinyin,\n       Lingua::KO::Romanize::Hangul."
  manpageQuestion1: What is the primary purpose of the perlunicook script?
  manpageQuestion2: How does the perlunicook script handle sorting of items in a hash with Asian characters?
  manpageQuestion3: Can you explain how the pad() function in perlunicook ensures proper alignment of item titles?

- prompt: |-
    You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.



    Manpage text:

    The Unicode::Tussle CPAN module includes many programs to help with
           working with Unicode, including these programs to fully or partly
           replace standard utilities: tcgrep instead of egrep, uniquote instead
           of cat -v or hexdump, uniwc instead of wc, unilook instead of look,
           unifmt instead of fmt, and ucsort instead of sort.  For exploring
           Unicode character names and character properties, see its uniprops,
           unichars, and uninames programs.  It also supplies these programs, all
           of which are general filters that do Unicode-y things: unititle and
           unicaps; uniwide and uninarrow; unisupers and unisubs; nfd, nfc, nfkd,
           and nfkc; and uc, lc, and tc.

           Finally, see the published Unicode Standard (page numbers are from
           version 6.0.0), including these specific annexes and technical reports:

           X3.13 Default Case Algorithms, page 113; X4.2  Case, pages 120X122;
           Case Mappings, page 166X172, especially Caseless Matching starting on
           page 170.
           UAX #44: Unicode Character Database
           UTS #18: Unicode Regular Expressions
           UAX #15: Unicode Normalization Forms
           UTS #10: Unicode Collation Algorithm
           UAX #29: Unicode Text Segmentation
           UAX #14: Unicode Line Breaking Algorithm
           UAX #11: East Asian Width
  manpageQuestion1: What is the primary purpose of the perlunicook resource?
  manpageQuestion2: How can you use perlunicook to process a file with Unicode characters and apply case folding?
  manpageQuestion3: What is an example of using perlunicook to normalize Unicode text into the NFC normalization form?

- prompt: "You are playing the role of a college professor. Here is some text copied from the manpages of the macOS resource `perlunicook`.\n\n\n\nManpage text:\n\nAUTHOR\n       Tom Christiansen <tchrist@perl.com> wrote this, with occasional\n       kibbitzing from Larry Wall and Jeffrey Friedl in the background.\n\nCOPYRIGHT AND LICENCE\n       Copyright X 2012 Tom Christiansen.\n\n       This program is free software; you may redistribute it and/or modify it\n       under the same terms as Perl itself.\n\n       Most of these examples taken from the current edition of the XCamel\n       BookX; that is, from the 4XX Edition of Programming Perl, Copyright X\n       2012 Tom Christiansen <et al.>, 2012-02-13 by OXReilly Media.  The code\n       itself is freely redistributable, and you are encouraged to transplant,\n       fold, spindle, and mutilate any of the examples in this manpage however\n       you please for inclusion into your own programs without any encumbrance\n       whatsoever.  Acknowledgement via code comment is polite but not\n       required.\n\nREVISION HISTORY\n       v1.0.0 X first public release, 2012-02-27\n\nperl v5.34.1\t\t\t  2022-02-19\t\t\tPERLUNICOOK(1)"
  manpageQuestion1: What is the primary purpose of the perlunicook tool?
  manpageQuestion2: How would you use perlunicook to process a string and perform Unicode normalization?
  manpageQuestion3: Can you provide an example of using perlunicook to handle a Unicode character in a specific normalization form?

